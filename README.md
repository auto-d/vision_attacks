# ♻️ Rotationally Invariant Adversarial Patches

[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/auto-d/vision_attacks/blob/main/attacks.ipynb)

This notebook borrows heavily from a tutorial originally created by Phillip Lippe and modified by Dr. Brinnae Bent for use in "Emerging Trends in Explainable AI" at Duke University. It demonstrates generation of adversarial patches for vision models that are rotation invariant.

-xox, 
Jason (Mooberry), 3 Nov 2025

---- 

Original Notebook: 
- [![View notebooks on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial10/Adversarial_Attacks.ipynb) 

Duke Notebook: 
- [![View notebooks on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/AIPI-590-XAI/Duke-AI-XAI/blob/main/adversarial-ai-example-notebooks/adversarial_attacks_patches.ipynb)
